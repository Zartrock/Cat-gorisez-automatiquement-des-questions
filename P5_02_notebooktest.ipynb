{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e5a2721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Error message \"error:0308010C:digital envelope...</td>\n",
       "      <td>&lt;p&gt;I created the default IntelliJ IDEA React p...</td>\n",
       "      <td>&lt;node.js&gt;&lt;reactjs&gt;&lt;webpack&gt;&lt;webstorm&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can I resolve the error \"The minCompileSdk...</td>\n",
       "      <td>&lt;p&gt;The error message:&lt;/p&gt;\\n&lt;blockquote&gt;\\n&lt;p&gt;Th...</td>\n",
       "      <td>&lt;java&gt;&lt;android&gt;&lt;kotlin&gt;&lt;gradle&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"You are running create-react-app 4.0.3 which ...</td>\n",
       "      <td>&lt;p&gt;I got an error while creating a React appli...</td>\n",
       "      <td>&lt;javascript&gt;&lt;reactjs&gt;&lt;npm-install&gt;&lt;yarnpkg&gt;&lt;npx&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bubble sort slower with -O3 than -O2 with GCC</td>\n",
       "      <td>&lt;p&gt;I made a &lt;a href=\"https://en.wikipedia.org/...</td>\n",
       "      <td>&lt;c&gt;&lt;gcc&gt;&lt;x86-64&gt;&lt;cpu-architecture&gt;&lt;compiler-op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Webpack build failing with ERR_OSSL_EVP_UNSUPP...</td>\n",
       "      <td>&lt;p&gt;I'm having an issue with a Webpack build pr...</td>\n",
       "      <td>&lt;webpack&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iOS 15 Navigation Bar Transparent</td>\n",
       "      <td>&lt;p&gt;My iOS app uses the storyboard for the UI a...</td>\n",
       "      <td>&lt;swift&gt;&lt;uinavigationcontroller&gt;&lt;ios15&gt;&lt;xcode13&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Resource linking fails on lStar</td>\n",
       "      <td>&lt;p&gt;I'm working on a React Native application. ...</td>\n",
       "      <td>&lt;android&gt;&lt;react-native&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Why is a segmentation fault not recoverable?</td>\n",
       "      <td>&lt;p&gt;Following &lt;a href=\"https://stackoverflow.co...</td>\n",
       "      <td>&lt;c++&gt;&lt;c&gt;&lt;exception&gt;&lt;segmentation-fault&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is this odd sorting algorithm?</td>\n",
       "      <td>&lt;p&gt;Some &lt;a href=\"https://stackoverflow.com/a/6...</td>\n",
       "      <td>&lt;python&gt;&lt;algorithm&gt;&lt;sorting&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Warning: Multiple merge bases detected. The li...</td>\n",
       "      <td>&lt;p&gt;In Azure Repos, I have created a PR from br...</td>\n",
       "      <td>&lt;git&gt;&lt;azure&gt;&lt;azure-devops&gt;&lt;azure-repos&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Error message \"error:0308010C:digital envelope...   \n",
       "1  How can I resolve the error \"The minCompileSdk...   \n",
       "2  \"You are running create-react-app 4.0.3 which ...   \n",
       "3      Bubble sort slower with -O3 than -O2 with GCC   \n",
       "4  Webpack build failing with ERR_OSSL_EVP_UNSUPP...   \n",
       "5                  iOS 15 Navigation Bar Transparent   \n",
       "6                    Resource linking fails on lStar   \n",
       "7       Why is a segmentation fault not recoverable?   \n",
       "8                What is this odd sorting algorithm?   \n",
       "9  Warning: Multiple merge bases detected. The li...   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I created the default IntelliJ IDEA React p...   \n",
       "1  <p>The error message:</p>\\n<blockquote>\\n<p>Th...   \n",
       "2  <p>I got an error while creating a React appli...   \n",
       "3  <p>I made a <a href=\"https://en.wikipedia.org/...   \n",
       "4  <p>I'm having an issue with a Webpack build pr...   \n",
       "5  <p>My iOS app uses the storyboard for the UI a...   \n",
       "6  <p>I'm working on a React Native application. ...   \n",
       "7  <p>Following <a href=\"https://stackoverflow.co...   \n",
       "8  <p>Some <a href=\"https://stackoverflow.com/a/6...   \n",
       "9  <p>In Azure Repos, I have created a PR from br...   \n",
       "\n",
       "                                                Tags  \n",
       "0              <node.js><reactjs><webpack><webstorm>  \n",
       "1                    <java><android><kotlin><gradle>  \n",
       "2   <javascript><reactjs><npm-install><yarnpkg><npx>  \n",
       "3  <c><gcc><x86-64><cpu-architecture><compiler-op...  \n",
       "4                                          <webpack>  \n",
       "5    <swift><uinavigationcontroller><ios15><xcode13>  \n",
       "6                            <android><react-native>  \n",
       "7            <c++><c><exception><segmentation-fault>  \n",
       "8                       <python><algorithm><sorting>  \n",
       "9            <git><azure><azure-devops><azure-repos>  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pickle\n",
    "import IPython.display\n",
    "from IPython.display import display\n",
    "\n",
    "data = pd.read_csv(r'C:\\Users\\sesa638933\\Desktop\\OC\\P5\\filtered_data.csv', usecols=['Id','Title', 'Body', 'Tags'], index_col='Id')\n",
    "data.reset_index(inplace=True)\n",
    "data.drop(columns='Id', inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92eb551e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dix première observations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Error message \"error:0308010C:digital envelope...</td>\n",
       "      <td>&lt;p&gt;I created the default IntelliJ IDEA React p...</td>\n",
       "      <td>&lt;node.js&gt;&lt;reactjs&gt;&lt;webpack&gt;&lt;webstorm&gt;</td>\n",
       "      <td>Error message \"error:0308010C:digital envelope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can I resolve the error \"The minCompileSdk...</td>\n",
       "      <td>&lt;p&gt;The error message:&lt;/p&gt;\\n&lt;blockquote&gt;\\n&lt;p&gt;Th...</td>\n",
       "      <td>&lt;java&gt;&lt;android&gt;&lt;kotlin&gt;&lt;gradle&gt;</td>\n",
       "      <td>How can I resolve the error \"The minCompileSdk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"You are running create-react-app 4.0.3 which ...</td>\n",
       "      <td>&lt;p&gt;I got an error while creating a React appli...</td>\n",
       "      <td>&lt;javascript&gt;&lt;reactjs&gt;&lt;npm-install&gt;&lt;yarnpkg&gt;&lt;npx&gt;</td>\n",
       "      <td>\"You are running create-react-app 4.0.3 which ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bubble sort slower with -O3 than -O2 with GCC</td>\n",
       "      <td>&lt;p&gt;I made a &lt;a href=\"https://en.wikipedia.org/...</td>\n",
       "      <td>&lt;c&gt;&lt;gcc&gt;&lt;x86-64&gt;&lt;cpu-architecture&gt;&lt;compiler-op...</td>\n",
       "      <td>Bubble sort slower with -O3 than -O2 with GCC ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Webpack build failing with ERR_OSSL_EVP_UNSUPP...</td>\n",
       "      <td>&lt;p&gt;I'm having an issue with a Webpack build pr...</td>\n",
       "      <td>&lt;webpack&gt;</td>\n",
       "      <td>Webpack build failing with ERR_OSSL_EVP_UNSUPP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iOS 15 Navigation Bar Transparent</td>\n",
       "      <td>&lt;p&gt;My iOS app uses the storyboard for the UI a...</td>\n",
       "      <td>&lt;swift&gt;&lt;uinavigationcontroller&gt;&lt;ios15&gt;&lt;xcode13&gt;</td>\n",
       "      <td>iOS 15 Navigation Bar Transparent &lt;p&gt;My iOS ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Resource linking fails on lStar</td>\n",
       "      <td>&lt;p&gt;I'm working on a React Native application. ...</td>\n",
       "      <td>&lt;android&gt;&lt;react-native&gt;</td>\n",
       "      <td>Resource linking fails on lStar &lt;p&gt;I'm working...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Why is a segmentation fault not recoverable?</td>\n",
       "      <td>&lt;p&gt;Following &lt;a href=\"https://stackoverflow.co...</td>\n",
       "      <td>&lt;c++&gt;&lt;c&gt;&lt;exception&gt;&lt;segmentation-fault&gt;</td>\n",
       "      <td>Why is a segmentation fault not recoverable? &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is this odd sorting algorithm?</td>\n",
       "      <td>&lt;p&gt;Some &lt;a href=\"https://stackoverflow.com/a/6...</td>\n",
       "      <td>&lt;python&gt;&lt;algorithm&gt;&lt;sorting&gt;</td>\n",
       "      <td>What is this odd sorting algorithm? &lt;p&gt;Some &lt;a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Warning: Multiple merge bases detected. The li...</td>\n",
       "      <td>&lt;p&gt;In Azure Repos, I have created a PR from br...</td>\n",
       "      <td>&lt;git&gt;&lt;azure&gt;&lt;azure-devops&gt;&lt;azure-repos&gt;</td>\n",
       "      <td>Warning: Multiple merge bases detected. The li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Error message \"error:0308010C:digital envelope...   \n",
       "1  How can I resolve the error \"The minCompileSdk...   \n",
       "2  \"You are running create-react-app 4.0.3 which ...   \n",
       "3      Bubble sort slower with -O3 than -O2 with GCC   \n",
       "4  Webpack build failing with ERR_OSSL_EVP_UNSUPP...   \n",
       "5                  iOS 15 Navigation Bar Transparent   \n",
       "6                    Resource linking fails on lStar   \n",
       "7       Why is a segmentation fault not recoverable?   \n",
       "8                What is this odd sorting algorithm?   \n",
       "9  Warning: Multiple merge bases detected. The li...   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I created the default IntelliJ IDEA React p...   \n",
       "1  <p>The error message:</p>\\n<blockquote>\\n<p>Th...   \n",
       "2  <p>I got an error while creating a React appli...   \n",
       "3  <p>I made a <a href=\"https://en.wikipedia.org/...   \n",
       "4  <p>I'm having an issue with a Webpack build pr...   \n",
       "5  <p>My iOS app uses the storyboard for the UI a...   \n",
       "6  <p>I'm working on a React Native application. ...   \n",
       "7  <p>Following <a href=\"https://stackoverflow.co...   \n",
       "8  <p>Some <a href=\"https://stackoverflow.com/a/6...   \n",
       "9  <p>In Azure Repos, I have created a PR from br...   \n",
       "\n",
       "                                                Tags  \\\n",
       "0              <node.js><reactjs><webpack><webstorm>   \n",
       "1                    <java><android><kotlin><gradle>   \n",
       "2   <javascript><reactjs><npm-install><yarnpkg><npx>   \n",
       "3  <c><gcc><x86-64><cpu-architecture><compiler-op...   \n",
       "4                                          <webpack>   \n",
       "5    <swift><uinavigationcontroller><ios15><xcode13>   \n",
       "6                            <android><react-native>   \n",
       "7            <c++><c><exception><segmentation-fault>   \n",
       "8                       <python><algorithm><sorting>   \n",
       "9            <git><azure><azure-devops><azure-repos>   \n",
       "\n",
       "                                                Post  \n",
       "0  Error message \"error:0308010C:digital envelope...  \n",
       "1  How can I resolve the error \"The minCompileSdk...  \n",
       "2  \"You are running create-react-app 4.0.3 which ...  \n",
       "3  Bubble sort slower with -O3 than -O2 with GCC ...  \n",
       "4  Webpack build failing with ERR_OSSL_EVP_UNSUPP...  \n",
       "5  iOS 15 Navigation Bar Transparent <p>My iOS ap...  \n",
       "6  Resource linking fails on lStar <p>I'm working...  \n",
       "7  Why is a segmentation fault not recoverable? <...  \n",
       "8  What is this odd sorting algorithm? <p>Some <a...  \n",
       "9  Warning: Multiple merge bases detected. The li...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Post'] = data.apply(lambda x: x['Title'] + ' ' + x['Body'] if x['Title'] == x['Title'] else x['Body'], axis=1)\n",
    "corpus = data['Post'].to_list()\n",
    "tags = data['Tags'].to_list()\n",
    "\n",
    "print(\"Dix première observations\")\n",
    "display(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a1f726d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premier élément de la liste corpus\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Error message \"error:0308010C:digital envelope routines::unsupported\" <p>I created the default IntelliJ IDEA React project and got this:</p>\\n<pre class=\"lang-none prettyprint-override\"><code>Error: error:0308010C:digital envelope routines::unsupported\\n    at new Hash (node:internal/crypto/hash:67:19)\\n    at Object.createHash (node:crypto:130:10)\\n    at module.exports (/Users/user/Programming Documents/WebServer/untitled/node_modules/webpack/lib/util/createHash.js:135:53)\\n    at NormalModule._initBuildHash (/Users/user/Programming Documents/WebServer/untitled/node_modules/webpack/lib/NormalModule.js:417:16)\\n    at handleParseError (/Users/user/Programming Documents/WebServer/untitled/node_modules/webpack/lib/NormalModule.js:471:10)\\n    at /Users/user/Programming Documents/WebServer/untitled/node_modules/webpack/lib/NormalModule.js:503:5\\n    at /Users/user/Programming Documents/WebServer/untitled/node_modules/webpack/lib/NormalModule.js:358:12\\n    at /Users/user/Programming Documents/WebServer/untitled/node_modules/loader-runner/lib/LoaderRunner.js:373:3\\n    at iterateNormalLoaders (/Users/user/Programming Documents/WebServer/untitled/node_modules/loader-runner/lib/LoaderRunner.js:214:10)\\n    at iterateNormalLoaders (/Users/user/Programming Documents/WebServer/untitled/node_modules/loader-runner/lib/LoaderRunner.js:221:10)\\n/Users/user/Programming Documents/WebServer/untitled/node_modules/react-scripts/scripts/start.js:19\\n  throw err;\\n  ^\\n</code></pre>\\n<p>It seems to be a recent issue - <em><a href=\"https://github.com/webpack/webpack/issues/14532\" rel=\"noreferrer\">webpack ran into this 4 days ago and is still working on it</a></em>.</p>\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Premier éléments de la liste tags\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<node.js><reactjs><webpack><webstorm>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurences dans le corpus: 2785\n",
      "Occurences dans les tags: 2785\n"
     ]
    }
   ],
   "source": [
    "print(\"Premier élément de la liste corpus\\n\")\n",
    "display(corpus[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Premier éléments de la liste tags\\n\")\n",
    "display(tags[0])\n",
    "\n",
    "print(f\"Occurences dans le corpus: {len(corpus)}\")\n",
    "print(f\"Occurences dans les tags: {len(tags)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5935d6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premier élément de la liste corpus sans html\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Error message \"error:0308010C:digital envelope routines::unsupported\" I created the default IntelliJ IDEA React project and got this: Error: error:0308010C:digital envelope routines::unsupported\\n    at new Hash (node:internal/crypto/hash:67:19)\\n    at Object.createHash (node:crypto:130:10)\\n    at module.exports (/Users/user/Programming Documents/WebServer/untitled/node_modules/webpack/lib/util/createHash.js:135:53)\\n    at NormalModule._initBuildHash (/Users/user/Programming Documents/WebServer/untitled/node_modules/webpack/lib/NormalModule.js:417:16)\\n    at handleParseError (/Users/user/Programming Documents/WebServer/untitled/node_modules/webpack/lib/NormalModule.js:471:10)\\n    at /Users/user/Programming Documents/WebServer/untitled/node_modules/webpack/lib/NormalModule.js:503:5\\n    at /Users/user/Programming Documents/WebServer/untitled/node_modules/webpack/lib/NormalModule.js:358:12\\n    at /Users/user/Programming Documents/WebServer/untitled/node_modules/loader-runner/lib/LoaderRunner.js:373:3\\n    at iterateNormalLoaders (/Users/user/Programming Documents/WebServer/untitled/node_modules/loader-runner/lib/LoaderRunner.js:214:10)\\n    at iterateNormalLoaders (/Users/user/Programming Documents/WebServer/untitled/node_modules/loader-runner/lib/LoaderRunner.js:221:10)\\n/Users/user/Programming Documents/WebServer/untitled/node_modules/react-scripts/scripts/start.js:19\\n  throw err;\\n  ^ It seems to be a recent issue - webpack ran into this 4 days ago and is still working on it .'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Occurences dans le corpus: 2785\n"
     ]
    }
   ],
   "source": [
    "def clean_html(text):\n",
    "    \"\"\"\n",
    "    Remove HTML from a text.\n",
    "    \n",
    "    Args:\n",
    "        text(String): Row text with html \n",
    "             \n",
    "    Returns:\n",
    "        cleaned String\n",
    "    \"\"\"\n",
    "    import lxml\n",
    "    import html5lib\n",
    "    from bs4 import BeautifulSoup\n",
    " \n",
    "    soup = BeautifulSoup(text, \"html5lib\")\n",
    "\n",
    "    for sent in soup(['style', 'script']):\n",
    "            sent.decompose()\n",
    "   \n",
    "        \n",
    "    return ' '.join(soup.stripped_strings)\n",
    "\n",
    "corpus_wo_html = [clean_html(text) for text in corpus]\n",
    "\n",
    "print(\"Premier élément de la liste corpus sans html\\n\")\n",
    "display(corpus_wo_html[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"Occurences dans le corpus: {len(corpus_wo_html)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bfbdb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    \"\"\"\n",
    "    Remove figures, punctuation, words shorter than two letters (excepted C or R) in a lowered text. \n",
    "    \n",
    "    Args:\n",
    "        text(String): Row text to clean\n",
    "        \n",
    "    Returns:\n",
    "       res(string): Cleaned text\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    pattern = re.compile(r'[^\\w]|[\\d_]')\n",
    "    \n",
    "    try: \n",
    "        res = re.sub(pattern,\" \", text).lower()\n",
    "    except TypeError:\n",
    "        return text\n",
    "    \n",
    "    res = res.split(\" \")\n",
    "    res = list(filter(lambda x: len(x)>3 , res))\n",
    "    res = \" \".join(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af2eaaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premier élément de la liste cleaned_corpus\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'error message error digital envelope routines unsupported created default intellij idea react project this error error digital envelope routines unsupported hash node internal crypto hash object createhash node crypto module exports users user programming documents webserver untitled node modules webpack util createhash normalmodule initbuildhash users user programming documents webserver untitled node modules webpack normalmodule handleparseerror users user programming documents webserver untitled node modules webpack normalmodule users user programming documents webserver untitled node modules webpack normalmodule users user programming documents webserver untitled node modules webpack normalmodule users user programming documents webserver untitled node modules loader runner loaderrunner iteratenormalloaders users user programming documents webserver untitled node modules loader runner loaderrunner iteratenormalloaders users user programming documents webserver untitled node modules loader runner loaderrunner users user programming documents webserver untitled node modules react scripts scripts start throw seems recent issue webpack into this days still working'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Premier élément de la liste cleaned_tags\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'node reactjs webpack webstorm'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Occurences dans le corpus nettoyé: 2785\n",
      "Occurences dans les tags nettoyés: 2785\n"
     ]
    }
   ],
   "source": [
    "cleaned_corpus = [text_cleaning(text) for text in corpus_wo_html]\n",
    "cleaned_tags = [text_cleaning(text).strip() for text in tags]\n",
    "\n",
    "\n",
    "print(\"Premier élément de la liste cleaned_corpus\\n\")\n",
    "display(cleaned_corpus[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Premier élément de la liste cleaned_tags\\n\")\n",
    "display(cleaned_tags[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"Occurences dans le corpus nettoyé: {len(cleaned_corpus)}\")\n",
    "print(f\"Occurences dans les tags nettoyés: {len(cleaned_tags)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c6aa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10060]\n",
      "[nltk_data]     Une tentative de connexion a échoué car le parti\n",
      "[nltk_data]     connecté n’a pas répondu convenablement au-delà d’une\n",
      "[nltk_data]     certaine durée ou une connexion établie a échoué car\n",
      "[nltk_data]     l’hôte de connexion n’a pas répondu>\n",
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] Une\n",
      "[nltk_data]     tentative de connexion a échoué car le parti connecté\n",
      "[nltk_data]     n’a pas répondu convenablement au-delà d’une certaine\n",
      "[nltk_data]     durée ou une connexion établie a échoué car l’hôte de\n",
      "[nltk_data]     connexion n’a pas répondu>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38e0b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize words of a text.\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "        text(String): Row text\n",
    "        \n",
    "    Returns\n",
    "    \n",
    "        res(list): Tokenized string.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    try:\n",
    "        res = word_tokenize(text, language='english')\n",
    "    except TypeError:\n",
    "        return text\n",
    "    \n",
    "    res = [token for token in res if token not in stop_words]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "915cc3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premier élément de la liste tokenized_corpus\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['error',\n",
       " 'message',\n",
       " 'error',\n",
       " 'digital',\n",
       " 'envelope',\n",
       " 'routines',\n",
       " 'unsupported',\n",
       " 'created',\n",
       " 'default',\n",
       " 'intellij',\n",
       " 'idea',\n",
       " 'react',\n",
       " 'project',\n",
       " 'error',\n",
       " 'error',\n",
       " 'digital',\n",
       " 'envelope',\n",
       " 'routines',\n",
       " 'unsupported',\n",
       " 'hash',\n",
       " 'node',\n",
       " 'internal',\n",
       " 'crypto',\n",
       " 'hash',\n",
       " 'object',\n",
       " 'createhash',\n",
       " 'node',\n",
       " 'crypto',\n",
       " 'module',\n",
       " 'exports',\n",
       " 'users',\n",
       " 'user',\n",
       " 'programming',\n",
       " 'documents',\n",
       " 'webserver',\n",
       " 'untitled',\n",
       " 'node',\n",
       " 'modules',\n",
       " 'webpack',\n",
       " 'util',\n",
       " 'createhash',\n",
       " 'normalmodule',\n",
       " 'initbuildhash',\n",
       " 'users',\n",
       " 'user',\n",
       " 'programming',\n",
       " 'documents',\n",
       " 'webserver',\n",
       " 'untitled',\n",
       " 'node',\n",
       " 'modules',\n",
       " 'webpack',\n",
       " 'normalmodule',\n",
       " 'handleparseerror',\n",
       " 'users',\n",
       " 'user',\n",
       " 'programming',\n",
       " 'documents',\n",
       " 'webserver',\n",
       " 'untitled',\n",
       " 'node',\n",
       " 'modules',\n",
       " 'webpack',\n",
       " 'normalmodule',\n",
       " 'users',\n",
       " 'user',\n",
       " 'programming',\n",
       " 'documents',\n",
       " 'webserver',\n",
       " 'untitled',\n",
       " 'node',\n",
       " 'modules',\n",
       " 'webpack',\n",
       " 'normalmodule',\n",
       " 'users',\n",
       " 'user',\n",
       " 'programming',\n",
       " 'documents',\n",
       " 'webserver',\n",
       " 'untitled',\n",
       " 'node',\n",
       " 'modules',\n",
       " 'webpack',\n",
       " 'normalmodule',\n",
       " 'users',\n",
       " 'user',\n",
       " 'programming',\n",
       " 'documents',\n",
       " 'webserver',\n",
       " 'untitled',\n",
       " 'node',\n",
       " 'modules',\n",
       " 'loader',\n",
       " 'runner',\n",
       " 'loaderrunner',\n",
       " 'iteratenormalloaders',\n",
       " 'users',\n",
       " 'user',\n",
       " 'programming',\n",
       " 'documents',\n",
       " 'webserver',\n",
       " 'untitled',\n",
       " 'node',\n",
       " 'modules',\n",
       " 'loader',\n",
       " 'runner',\n",
       " 'loaderrunner',\n",
       " 'iteratenormalloaders',\n",
       " 'users',\n",
       " 'user',\n",
       " 'programming',\n",
       " 'documents',\n",
       " 'webserver',\n",
       " 'untitled',\n",
       " 'node',\n",
       " 'modules',\n",
       " 'loader',\n",
       " 'runner',\n",
       " 'loaderrunner',\n",
       " 'users',\n",
       " 'user',\n",
       " 'programming',\n",
       " 'documents',\n",
       " 'webserver',\n",
       " 'untitled',\n",
       " 'node',\n",
       " 'modules',\n",
       " 'react',\n",
       " 'scripts',\n",
       " 'scripts',\n",
       " 'start',\n",
       " 'throw',\n",
       " 'seems',\n",
       " 'recent',\n",
       " 'issue',\n",
       " 'webpack',\n",
       " 'days',\n",
       " 'still',\n",
       " 'working']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Longueur du premier éléments de liste tokenized_corpus: 139\n",
      "\n",
      "\n",
      "Premier élément de la liste tokenized_tags\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['node', 'reactjs', 'webpack', 'webstorm']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Occurences dans le corpus tokenizé: 2785\n",
      "Occurences dans la liste des tags: 2785\n"
     ]
    }
   ],
   "source": [
    "tokenized_corpus = [tokenize(text) for text in cleaned_corpus]\n",
    "tokenized_tags = [tokenize(text) for text in cleaned_tags]\n",
    "\n",
    "print(\"Premier élément de la liste tokenized_corpus\\n\")\n",
    "display(tokenized_corpus[0])\n",
    "print(\"\\n\")\n",
    "print(f\"Longueur du premier éléments de liste tokenized_corpus: {len(tokenized_corpus[0])}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Premier élément de la liste tokenized_tags\\n\")\n",
    "display(tokenized_tags[0])\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(f\"Occurences dans le corpus tokenizé: {len(tokenized_corpus)}\")\n",
    "print(f\"Occurences dans la liste des tags: {len(tokenized_tags)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dc35a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [WinError 10060] Une tentative de connexion a échoué\n",
      "[nltk_data]     car le parti connecté n’a pas répondu convenablement\n",
      "[nltk_data]     au-delà d’une certaine durée ou une connexion établie\n",
      "[nltk_data]     a échoué car l’hôte de connexion n’a pas répondu>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premier élément de la liste noun_corpus\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['error',\n",
       " 'message',\n",
       " 'error',\n",
       " 'envelope',\n",
       " 'default',\n",
       " 'intellij',\n",
       " 'idea',\n",
       " 'react',\n",
       " 'project',\n",
       " 'error',\n",
       " 'error',\n",
       " 'envelope',\n",
       " 'node',\n",
       " 'crypto',\n",
       " 'hash',\n",
       " 'createhash',\n",
       " 'node',\n",
       " 'crypto',\n",
       " 'module',\n",
       " 'node',\n",
       " 'createhash',\n",
       " 'normalmodule',\n",
       " 'initbuildhash',\n",
       " 'node',\n",
       " 'handleparseerror',\n",
       " 'node',\n",
       " 'node',\n",
       " 'node',\n",
       " 'node',\n",
       " 'runner',\n",
       " 'loaderrunner',\n",
       " 'node',\n",
       " 'runner',\n",
       " 'loaderrunner',\n",
       " 'node',\n",
       " 'runner',\n",
       " 'loaderrunner',\n",
       " 'node',\n",
       " 'throw',\n",
       " 'issue',\n",
       " 'webpack']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Longueur du premier éléments de liste noun_corpus: 41\n",
      "\n",
      "\n",
      "Occurences dans le corpus tokenizé: 2785\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def filtering_nouns(tokens):\n",
    "    \"\"\"\n",
    "    Filter singular nouns\n",
    "    \n",
    "    Args:\n",
    "        tokens(list): A list o tokens\n",
    "        \n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "        res(list): Filtered token list\n",
    "    \"\"\" \n",
    "    \n",
    "    import nltk\n",
    "    \n",
    "    res = nltk.pos_tag(tokens)\n",
    "    \n",
    "    res = [token[0] for token in res if token[1] == 'NN']\n",
    "    \n",
    "    return res\n",
    "\n",
    "noun_corpus = [filtering_nouns(tokens) for tokens in tokenized_corpus]\n",
    "\n",
    "print(\"Premier élément de la liste noun_corpus\\n\")\n",
    "display(noun_corpus[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"Longueur du premier éléments de liste noun_corpus: {len(noun_corpus[0])}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"Occurences dans le corpus tokenizé: {len(noun_corpus)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cd7340d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [WinError 10060] Une\n",
      "[nltk_data]     tentative de connexion a échoué car le parti connecté\n",
      "[nltk_data]     n’a pas répondu convenablement au-delà d’une certaine\n",
      "[nltk_data]     durée ou une connexion établie a échoué car l’hôte de\n",
      "[nltk_data]     connexion n’a pas répondu>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premier élément de la liste lemmatized_corpus\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['error',\n",
       " 'message',\n",
       " 'error',\n",
       " 'envelope',\n",
       " 'default',\n",
       " 'intellij',\n",
       " 'idea',\n",
       " 'react',\n",
       " 'project',\n",
       " 'error',\n",
       " 'error',\n",
       " 'envelope',\n",
       " 'node',\n",
       " 'crypto',\n",
       " 'hash',\n",
       " 'createhash',\n",
       " 'node',\n",
       " 'crypto',\n",
       " 'module',\n",
       " 'node',\n",
       " 'createhash',\n",
       " 'normalmodule',\n",
       " 'initbuildhash',\n",
       " 'node',\n",
       " 'handleparseerror',\n",
       " 'node',\n",
       " 'node',\n",
       " 'node',\n",
       " 'node',\n",
       " 'runner',\n",
       " 'loaderrunner',\n",
       " 'node',\n",
       " 'runner',\n",
       " 'loaderrunner',\n",
       " 'node',\n",
       " 'runner',\n",
       " 'loaderrunner',\n",
       " 'node',\n",
       " 'throw',\n",
       " 'issue',\n",
       " 'webpack']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Longueur du premier éléments de liste lemmatized_corpus: 41\n",
      "\n",
      "\n",
      "Premier élément de la liste lemmatized_tags\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['node', 'reactjs', 'webpack', 'webstorm']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurences dans le corpus lemmatisé: 2785\n",
      "Occurences dans les tags lemmatisés: 2785\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "def lemmatization(tokens):\n",
    "    \"\"\"\n",
    "    Transform tokens into lems \n",
    "    \n",
    "    Args:\n",
    "        tokens(list): List of tokens\n",
    "        \n",
    "    Returns:\n",
    "        lemmatized(list): List of lemmatized tokens\n",
    "    \"\"\"\n",
    "    import nltk\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        lemmatized.append(lemmatizer.lemmatize(token))\n",
    "        \n",
    "    return lemmatized\n",
    "\n",
    "lemmatized_corpus = [lemmatization(tokens) for tokens in noun_corpus]\n",
    "lemmatized_tags = [lemmatization(tokens) for tokens in tokenized_tags]\n",
    "\n",
    "tags_wo_blanks = []\n",
    "for tokens in lemmatized_tags:\n",
    "    tokens = [token for token in tokens if len(token)>1]\n",
    "    tags_wo_blanks.append(tokens)\n",
    "\n",
    "print(\"Premier élément de la liste lemmatized_corpus\\n\")\n",
    "display(lemmatized_corpus[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"Longueur du premier éléments de liste lemmatized_corpus: {len(lemmatized_corpus[0])}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Premier élément de la liste lemmatized_tags\\n\")\n",
    "display(tags_wo_blanks[0])\n",
    "\n",
    "\n",
    "print(f\"Occurences dans le corpus lemmatisé: {len(lemmatized_corpus)}\")\n",
    "print(f\"Occurences dans les tags lemmatisés: {len(tags_wo_blanks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15205009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeysView(environ({'ALLUSERSPROFILE': 'C:\\\\ProgramData', 'APPDATA': 'C:\\\\Users\\\\sesa638933\\\\AppData\\\\Roaming', 'COMMONPROGRAMFILES': 'C:\\\\Program Files\\\\Common Files', 'COMMONPROGRAMFILES(X86)': 'C:\\\\Program Files (x86)\\\\Common Files', 'COMMONPROGRAMW6432': 'C:\\\\Program Files\\\\Common Files', 'COMPUTERNAME': 'WTFRLVSE203097L', 'COMSPEC': 'C:\\\\WINDOWS\\\\system32\\\\cmd.exe', 'DEFLOGDIR': 'C:\\\\ProgramData\\\\McAfee\\\\Endpoint Security\\\\Logs', 'DRIVERDATA': 'C:\\\\Windows\\\\System32\\\\Drivers\\\\DriverData', 'FPS_BROWSER_APP_PROFILE_STRING': 'Internet Explorer', 'FPS_BROWSER_USER_PROFILE_STRING': 'Default', 'HOMEDRIVE': 'C:', 'HOMEPATH': '\\\\Users\\\\sesa638933', 'LOCALAPPDATA': 'C:\\\\Users\\\\sesa638933\\\\AppData\\\\Local', 'LOGONSERVER': '\\\\\\\\WDEUR20', 'NO_PROXY': '<local_addresses> : localhost,127.0.0.1,10.128.0.0/16,10.214.0.0/16,172.20.0.0/16,172.30.0.0/16,10.234.0.0/16,172.30.0.0/16,192.168.0.0/16,10.179.0.0/16,139.158.0.0/16,github.schneider-electric.com,teamforge.schneider-electric.com,box.com,*.ci-ffaas.schneider-electric.com,*.eur.gad.schneider-electric.com,directory.schneider-electric.com,teamforge.schneider-electric.com,*.spice.schneider-electric.com,spice.schneider-electric.com,thot.schneider-electric.com,digital-brandbook.schneider-electric.com,fs.schneider-electric.com,spiceapps.schneider-electric.com,othello.fr.schneider-electric.com,sgweb,spiceportal.schneider-electric.com,s-sewiki,intranet.de.schneider-electric.com,mobileplatform.schneider-electric.com,de-mhf-cm.schneider-electric.com,aafr0110.schneider-electric.com,semedia.schneider-electric.com,global-brick-catalogue.schneider-electric.com,pso.schneider-electric.com,online.schneider-electric.com,sopna01.aut.schneider-electric.com,s-jira,teamwork.schneider-electric.com,s-ew-iecsvn,documents-svn,ipo.schneider-electric.com,eur-it-support.schneider-electric.com,ocp.schneider-electric.com,qkrintra.schneider-electric.com,testhttp.schneider-electric.com,shoppingkiosk.schneider-electric.com,eprocurement.fr.schneider-electric.com,brand.schneider-electric.com,hotlinet.schneider-electric.com,2929it.schneider-electric.com,edms.schneider-electric.com,appsgovernance.schneider-electric.com,pace.schneider-electric.com,dces.schneider-electric.com,netapp.apc.com,bricks.schneider-electric.com,2929chatsupport.schneider-electric.com,isee.schneider-electric.com,eccos.schneider-electric.com,industry.vcampus.schneider-electric.com,identify.schneider-electric.com,tableau.schneider-electric.com,swebi.schneider-electric.com,global-artifacts.se.com\\n', 'NUMBER_OF_PROCESSORS': '8', 'OS': 'Windows_NT', 'PATH': 'C:\\\\Users\\\\sesa638933\\\\Anaconda3\\\\conda;C:\\\\Users\\\\sesa638933\\\\Anaconda3\\\\conda\\\\Library\\\\mingw-w64\\\\bin;C:\\\\Users\\\\sesa638933\\\\Anaconda3\\\\conda\\\\Library\\\\usr\\\\bin;C:\\\\Users\\\\sesa638933\\\\Anaconda3\\\\conda\\\\Library\\\\bin;C:\\\\Users\\\\sesa638933\\\\Anaconda3\\\\conda\\\\Scripts;C:\\\\WINDOWS\\\\system32;C:\\\\WINDOWS;C:\\\\WINDOWS\\\\System32\\\\Wbem;C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\WINDOWS\\\\System32\\\\OpenSSH\\\\;C:\\\\Program Files\\\\1E\\\\Client\\\\Extensibility\\\\NomadBranch;C:\\\\Program Files (x86)\\\\Windows Imaging\\\\;C:\\\\Users\\\\sesa638933\\\\maieul\\\\cmd;C:\\\\Users\\\\sesa638933\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Program Files\\\\JetBrains\\\\PyCharm Community Edition 2021.2.2\\\\bin;;C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2021.2.2\\\\bin;;C:\\\\Users\\\\sesa638933\\\\AppData\\\\Local\\\\Box\\\\Box Edit\\\\;C:\\\\Users\\\\sesa638933\\\\maieul\\\\bin', 'PATHEXT': '.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC', 'PROCESSOR_ARCHITECTURE': 'AMD64', 'PROCESSOR_IDENTIFIER': 'Intel64 Family 6 Model 142 Stepping 12, GenuineIntel', 'PROCESSOR_LEVEL': '6', 'PROCESSOR_REVISION': '8e0c', 'PROGRAMDATA': 'C:\\\\ProgramData', 'PROGRAMFILES': 'C:\\\\Program Files', 'PROGRAMFILES(X86)': 'C:\\\\Program Files (x86)', 'PROGRAMW6432': 'C:\\\\Program Files', 'PSMODULEPATH': 'C:\\\\Program Files\\\\WindowsPowerShell\\\\Modules;C:\\\\WINDOWS\\\\system32\\\\WindowsPowerShell\\\\v1.0\\\\Modules;C:\\\\Program Files (x86)\\\\Microsoft Azure Information Protection\\\\Powershell', 'PUBLIC': 'C:\\\\Users\\\\Public', 'PYCHARM': 'C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2021.2.2\\\\bin;', 'PYCHARM COMMUNITY EDITION': 'C:\\\\Program Files\\\\JetBrains\\\\PyCharm Community Edition 2021.2.2\\\\bin;', 'SESSIONNAME': 'Console', 'SYSTEMDRIVE': 'C:', 'SYSTEMROOT': 'C:\\\\WINDOWS', 'TEMP': 'C:\\\\Users\\\\SESA63~1\\\\AppData\\\\Local\\\\Temp', 'TMP': 'C:\\\\Users\\\\SESA63~1\\\\AppData\\\\Local\\\\Temp', 'UATDATA': 'C:\\\\WINDOWS\\\\CCM\\\\UATData\\\\D9F8C395-CAB8-491d-B8AC-179A1FE1BE77', 'USERDNSDOMAIN': 'EUR.GAD.SCHNEIDER-ELECTRIC.COM', 'USERDOMAIN': 'EUR', 'USERDOMAIN_ROAMINGPROFILE': 'EUR', 'USERNAME': 'SESA638933', 'USERPROFILE': 'C:\\\\Users\\\\sesa638933', 'WINDIR': 'C:\\\\WINDOWS', 'ZES_ENABLE_SYSMAN': '1', '__PSLOCKDOWNPOLICY': '0', 'CONDA_PREFIX': 'C:\\\\Users\\\\sesa638933\\\\Anaconda3\\\\conda', 'JPY_INTERRUPT_EVENT': '2944', 'IPY_INTERRUPT_EVENT': '2944', 'JPY_PARENT_PID': '3044', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline', 'KMP_DUPLICATE_LIB_OK': 'True', 'KMP_INIT_AT_FORK': 'FALSE'}))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36f888c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations restantes du corpus original: 2785\n"
     ]
    }
   ],
   "source": [
    "print(f\"Observations restantes du corpus original: {data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7978324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observations restantes du corpus traité: 2739\n"
     ]
    }
   ],
   "source": [
    "joined_corpus = [\" \".join(text) for text in lemmatized_corpus]\n",
    "corpus_df = pd.DataFrame(joined_corpus, columns=['preprocessed_text'])\n",
    "corpus_df['len_text'] = corpus_df['preprocessed_text'].apply(lambda x: len(x))\n",
    "\n",
    "joined_tags = [\" \".join(tags) for tags in tags_wo_blanks]\n",
    "tag_df = pd.DataFrame(joined_tags, columns=['preprocessed_tags'])\n",
    "tag_df['len_tags'] = tag_df['preprocessed_tags'].apply(lambda x: len(x))\n",
    "\n",
    "corpus_tag_df = pd.concat([corpus_df, tag_df], axis=1)\n",
    "\n",
    "empty_data_idx = corpus_tag_df[(corpus_tag_df['len_text']==0) | (corpus_tag_df['len_tags']==0)].index\n",
    "\n",
    "\n",
    "\n",
    "empty_data_idx\n",
    "\n",
    "corpus_tag_df\n",
    "\n",
    "data\n",
    "\n",
    "corpus_tag_df.drop(labels=empty_data_idx, inplace=True)\n",
    "data.drop(index=empty_data_idx, axis = 0, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"observations restantes du corpus traité: {corpus_tag_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb2a444e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post</th>\n",
       "      <th>splitted_text</th>\n",
       "      <th>splitted_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Error message \"error:0308010C:digital envelope...</td>\n",
       "      <td>[error, message, error, envelope, default, int...</td>\n",
       "      <td>[node, reactjs, webpack, webstorm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can I resolve the error \"The minCompileSdk...</td>\n",
       "      <td>[error, mincompilesdk, dependency, java, kotli...</td>\n",
       "      <td>[java, android, kotlin, gradle]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"You are running create-react-app 4.0.3 which ...</td>\n",
       "      <td>[create, react, release, error, application]</td>\n",
       "      <td>[javascript, reactjs, install, yarnpkg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bubble sort slower with -O3 than -O2 with GCC ...</td>\n",
       "      <td>[sort, sort, implementation, performance, flag...</td>\n",
       "      <td>[architecture, compiler, optimization]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Webpack build failing with ERR_OSSL_EVP_UNSUPP...</td>\n",
       "      <td>[webpack, build, issue, webpack, process, erro...</td>\n",
       "      <td>[webpack]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iOS 15 Navigation Bar Transparent &lt;p&gt;My iOS ap...</td>\n",
       "      <td>[navigation, transparent, tint, background, co...</td>\n",
       "      <td>[swift, uinavigationcontroller, xcode]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Resource linking fails on lStar &lt;p&gt;I'm working...</td>\n",
       "      <td>[resource, application, android, environment, ...</td>\n",
       "      <td>[android, react, native]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Why is a segmentation fault not recoverable? &lt;...</td>\n",
       "      <td>[segmentation, fault, question, mine, state, k...</td>\n",
       "      <td>[exception, segmentation, fault]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is this odd sorting algorithm? &lt;p&gt;Some &lt;a...</td>\n",
       "      <td>[algorithm, answer, swap, note, range, make, o...</td>\n",
       "      <td>[python, algorithm, sorting]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Warning: Multiple merge bases detected. The li...</td>\n",
       "      <td>[merge, list, azure, repos, branch, branch, me...</td>\n",
       "      <td>[azure, azure, devops, azure, repos]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Post  \\\n",
       "0  Error message \"error:0308010C:digital envelope...   \n",
       "1  How can I resolve the error \"The minCompileSdk...   \n",
       "2  \"You are running create-react-app 4.0.3 which ...   \n",
       "3  Bubble sort slower with -O3 than -O2 with GCC ...   \n",
       "4  Webpack build failing with ERR_OSSL_EVP_UNSUPP...   \n",
       "5  iOS 15 Navigation Bar Transparent <p>My iOS ap...   \n",
       "6  Resource linking fails on lStar <p>I'm working...   \n",
       "7  Why is a segmentation fault not recoverable? <...   \n",
       "8  What is this odd sorting algorithm? <p>Some <a...   \n",
       "9  Warning: Multiple merge bases detected. The li...   \n",
       "\n",
       "                                       splitted_text  \\\n",
       "0  [error, message, error, envelope, default, int...   \n",
       "1  [error, mincompilesdk, dependency, java, kotli...   \n",
       "2       [create, react, release, error, application]   \n",
       "3  [sort, sort, implementation, performance, flag...   \n",
       "4  [webpack, build, issue, webpack, process, erro...   \n",
       "5  [navigation, transparent, tint, background, co...   \n",
       "6  [resource, application, android, environment, ...   \n",
       "7  [segmentation, fault, question, mine, state, k...   \n",
       "8  [algorithm, answer, swap, note, range, make, o...   \n",
       "9  [merge, list, azure, repos, branch, branch, me...   \n",
       "\n",
       "                             splitted_tags  \n",
       "0       [node, reactjs, webpack, webstorm]  \n",
       "1          [java, android, kotlin, gradle]  \n",
       "2  [javascript, reactjs, install, yarnpkg]  \n",
       "3   [architecture, compiler, optimization]  \n",
       "4                                [webpack]  \n",
       "5   [swift, uinavigationcontroller, xcode]  \n",
       "6                 [android, react, native]  \n",
       "7         [exception, segmentation, fault]  \n",
       "8             [python, algorithm, sorting]  \n",
       "9     [azure, azure, devops, azure, repos]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tag_df['splitted_text'] = corpus_tag_df['preprocessed_text'].apply(lambda x: x.split(' ') )\n",
    "corpus_tag_df['splitted_tags'] = corpus_tag_df['preprocessed_tags'].apply(lambda x: x.split(' ') )\n",
    "\n",
    "filtered_corpus = corpus_tag_df['splitted_text'].to_list()\n",
    "filtered_tags = corpus_tag_df['splitted_tags'].to_list()\n",
    "filtered_original_posts = data['Post'].to_list()\n",
    "\n",
    "filtered_tokenized_vs_original = pd.concat([data['Post'],\n",
    "                                            corpus_tag_df['splitted_text'], \n",
    "                                            corpus_tag_df['splitted_tags']],\n",
    "                                            axis=1)\n",
    "\n",
    "filtered_tokenized_vs_original.to_csv(r\"C:\\Users\\sesa638933\\Desktop\\OC\\P5\\cleaned_corpus.csv\", index=False)\n",
    "filtered_tokenized_vs_original.to_pickle(r'C:\\Users\\sesa638933\\Desktop\\OC\\P5\\cleaned_corpus.pkl')\n",
    "\n",
    "filtered_tokenized_vs_original.head(10)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0abb3de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tokens du corpus 19426\n",
      "Affichage des 20 tokens les plus utilisés\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>java</th>\n",
       "      <td>4223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>2926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>2273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>version</th>\n",
       "      <td>2244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>1834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <td>1811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import</th>\n",
       "      <td>1795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http</th>\n",
       "      <td>1720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return</th>\n",
       "      <td>1298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>1188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>function</th>\n",
       "      <td>1144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>1118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>path</th>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>1006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>project</th>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Frequency\n",
       "Word               \n",
       "java           4223\n",
       "error          2926\n",
       "name           2273\n",
       "version        2244\n",
       "file           2013\n",
       "class          1834\n",
       "code           1811\n",
       "import         1795\n",
       "http           1720\n",
       "return         1298\n",
       "line           1250\n",
       "value          1242\n",
       "type           1188\n",
       "function       1144\n",
       "const          1118\n",
       "path           1033\n",
       "python         1006\n",
       "index           963\n",
       "test            956\n",
       "project         936"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_word_distribution(corpus):\n",
    "    \"\"\"\n",
    "    Build corpus word distribution\n",
    "    \n",
    "    Args:\n",
    "        Corpus(List of lists): Original corpus\n",
    "    \n",
    "    Returns:\n",
    "        \n",
    "        word_dist_df(DataFrame): Word distribution of the corpus\n",
    "    \"\"\"\n",
    "    \n",
    "    from nltk import FreqDist\n",
    "    word_corpus = [token for token_list in corpus for token in token_list]\n",
    "    word_dist = FreqDist(word_corpus)\n",
    "    word_dist_df = pd.DataFrame(word_dist.items(), columns=['Word', 'Frequency']).set_index('Word')\n",
    "    word_dist_df.sort_values(\"Frequency\", ascending=False, inplace=True)\n",
    "\n",
    "    return word_dist_df\n",
    "\n",
    "word_dist = build_word_distribution(filtered_corpus)\n",
    "\n",
    "print(f\"Nombre de tokens du corpus {word_dist.shape[0]}\")\n",
    "print(\"Affichage des 20 tokens les plus utilisés\")\n",
    "display(word_dist.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f4d5879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 des tags les plus utilisés\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>android</th>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>javascript</th>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>java</th>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reactjs</th>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>react</th>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studio</th>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node</th>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flutter</th>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google</th>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visual</th>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>typescript</th>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>github</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>docker</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spring</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>azure</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compose</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kotlin</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angular</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swift</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Frequency\n",
       "Word                 \n",
       "python            515\n",
       "android           414\n",
       "javascript        283\n",
       "java              246\n",
       "reactjs           201\n",
       "react             165\n",
       "studio            155\n",
       "node              130\n",
       "flutter           127\n",
       "google            122\n",
       "visual            120\n",
       "typescript        107\n",
       "github            105\n",
       "docker            105\n",
       "spring            104\n",
       "azure              84\n",
       "compose            81\n",
       "kotlin             77\n",
       "angular            76\n",
       "swift              74"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tags: 1883\n"
     ]
    }
   ],
   "source": [
    "tag_dist = build_word_distribution(filtered_tags)\n",
    "print(\"Top 20 des tags les plus utilisés\")\n",
    "display(tag_dist.head(20))\n",
    "print(f\"Nombre de tags: {len(tag_dist)}\")\n",
    "first_200_tags = tag_dist[0:200].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23749b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations restantes dans le corpus original: 2739\n"
     ]
    }
   ],
   "source": [
    "print(f\"Observations restantes dans le corpus original: {data.shape[0]}\")\n",
    "filtered_corpus_tag_df = corpus_tag_df.copy()\n",
    "filtered_corpus_tag_df['tags_in_top200'] = filtered_corpus_tag_df['splitted_tags'].apply(lambda tags: [tag for tag in tags if tag in first_200_tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05aa2a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations restantes dans le coprus traité: 2549\n"
     ]
    }
   ],
   "source": [
    "filtered_corpus_tag_df['len_tags_in_top200'] = filtered_corpus_tag_df['tags_in_top200'].apply(lambda x: len(x))\n",
    "missing_filtered_data = filtered_corpus_tag_df[filtered_corpus_tag_df['len_tags_in_top200'] == 0].index\n",
    "\n",
    "filtered_corpus_tag_df.drop(index=missing_filtered_data, inplace=True)\n",
    "data.drop(index=missing_filtered_data, inplace=True)\n",
    "print(f\"Observations restantes dans le coprus traité: {filtered_corpus_tag_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e9ab7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "top200_corpus = filtered_corpus_tag_df['splitted_text'].to_list()\n",
    "top200_joined_corpus = filtered_corpus_tag_df['preprocessed_text'].to_list()\n",
    "top200_tags = filtered_corpus_tag_df['tags_in_top200'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72062013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tokens du corpus 16985\n",
      "Affichage des 20 tokens les plus utilisés\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>java</th>\n",
       "      <td>4219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <td>2788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>2188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>version</th>\n",
       "      <td>2166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <td>1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import</th>\n",
       "      <td>1777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>1746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <td>1710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http</th>\n",
       "      <td>1637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return</th>\n",
       "      <td>1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>1194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>1127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>function</th>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>path</th>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>module</th>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Frequency\n",
       "Word               \n",
       "java           4219\n",
       "error          2788\n",
       "name           2188\n",
       "version        2166\n",
       "file           1942\n",
       "import         1777\n",
       "class          1746\n",
       "code           1710\n",
       "http           1637\n",
       "return         1226\n",
       "line           1210\n",
       "value          1194\n",
       "type           1127\n",
       "function       1037\n",
       "const          1032\n",
       "path           1024\n",
       "python         1003\n",
       "module          921\n",
       "index           917\n",
       "test            909"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre des tokens ayant plus de 1000 occurences sur le corpus filtré\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dist_top200 = build_word_distribution(top200_corpus)\n",
    "print(f\"Nombre de tokens du corpus {word_dist_top200.shape[0]}\")\n",
    "print(\"Affichage des 20 tokens les plus utilisés\")\n",
    "display(word_dist_top200.head(20))\n",
    "print(\"Nombre des tokens ayant plus de 1000 occurences sur le corpus filtré\")\n",
    "word_dist_top200[word_dist_top200[\"Frequency\"]>=1000].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19681477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 des tags les plus utilisés\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>android</th>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>javascript</th>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>java</th>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reactjs</th>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>react</th>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studio</th>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node</th>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flutter</th>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google</th>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visual</th>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>typescript</th>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>docker</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>github</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spring</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>azure</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compose</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kotlin</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angular</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swift</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Frequency\n",
       "Word                 \n",
       "python            515\n",
       "android           414\n",
       "javascript        283\n",
       "java              246\n",
       "reactjs           201\n",
       "react             165\n",
       "studio            155\n",
       "node              130\n",
       "flutter           127\n",
       "google            122\n",
       "visual            120\n",
       "typescript        107\n",
       "docker            105\n",
       "github            105\n",
       "spring            104\n",
       "azure              84\n",
       "compose            81\n",
       "kotlin             77\n",
       "angular            76\n",
       "swift              74"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tags: 200\n"
     ]
    }
   ],
   "source": [
    "tag_dist_top_200 = build_word_distribution(top200_tags)\n",
    "print(\"Top 20 des tags les plus utilisés\")\n",
    "display(tag_dist_top_200.head(20))\n",
    "print(f\"Nombre de tags: {len(tag_dist_top_200)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a887f672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affichage des 10 premiers posts vectorisés via le modèle de TF-IDF\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>java</th>\n",
       "      <th>error</th>\n",
       "      <th>name</th>\n",
       "      <th>version</th>\n",
       "      <th>file</th>\n",
       "      <th>import</th>\n",
       "      <th>class</th>\n",
       "      <th>code</th>\n",
       "      <th>http</th>\n",
       "      <th>return</th>\n",
       "      <th>line</th>\n",
       "      <th>value</th>\n",
       "      <th>type</th>\n",
       "      <th>function</th>\n",
       "      <th>const</th>\n",
       "      <th>path</th>\n",
       "      <th>python</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.592482</td>\n",
       "      <td>0.684021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.425536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.969166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584327</td>\n",
       "      <td>0.150171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.351158</td>\n",
       "      <td>0.294742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370111</td>\n",
       "      <td>0.537442</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.621957</td>\n",
       "      <td>0.783052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.725276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.931092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       java     error      name  version      file    import  class      code  \\\n",
       "0  0.000000  1.000000  0.000000      0.0  0.000000  0.000000    0.0  0.000000   \n",
       "1  0.592482  0.684021  0.000000      0.0  0.425536  0.000000    0.0  0.000000   \n",
       "2  0.000000  1.000000  0.000000      0.0  0.000000  0.000000    0.0  0.000000   \n",
       "3  0.000000  0.000000  0.000000      0.0  0.000000  0.000000    0.0  0.246409   \n",
       "4  0.000000  0.584327  0.150171      0.0  0.000000  0.000000    0.0  0.351158   \n",
       "5  0.000000  0.000000  0.000000      0.0  0.000000  0.000000    0.0  0.621957   \n",
       "6  0.000000  1.000000  0.000000      0.0  0.000000  0.000000    0.0  0.000000   \n",
       "7  0.000000  0.000000  0.688459      0.0  0.000000  0.725276    0.0  0.000000   \n",
       "8  0.000000  0.000000  0.000000      0.0  0.000000  0.000000    0.0  0.000000   \n",
       "9  0.000000  0.000000  0.000000      0.0  0.000000  0.000000    0.0  0.000000   \n",
       "\n",
       "       http    return  line     value  type  function     const      path  \\\n",
       "0  0.000000  0.000000   0.0  0.000000   0.0       0.0  0.000000  0.000000   \n",
       "1  0.000000  0.000000   0.0  0.000000   0.0       0.0  0.000000  0.000000   \n",
       "2  0.000000  0.000000   0.0  0.000000   0.0       0.0  0.000000  0.000000   \n",
       "3  0.000000  0.969166   0.0  0.000000   0.0       0.0  0.000000  0.000000   \n",
       "4  0.294742  0.000000   0.0  0.000000   0.0       0.0  0.370111  0.537442   \n",
       "5  0.783052  0.000000   0.0  0.000000   0.0       0.0  0.000000  0.000000   \n",
       "6  0.000000  0.000000   0.0  0.000000   0.0       0.0  0.000000  0.000000   \n",
       "7  0.000000  0.000000   0.0  0.000000   0.0       0.0  0.000000  0.000000   \n",
       "8  0.000000  0.000000   0.0  0.000000   0.0       0.0  0.000000  0.000000   \n",
       "9  0.000000  0.000000   0.0  0.931092   0.0       0.0  0.000000  0.000000   \n",
       "\n",
       "     python  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.000000  \n",
       "4  0.000000  \n",
       "5  0.000000  \n",
       "6  0.000000  \n",
       "7  0.000000  \n",
       "8  0.000000  \n",
       "9  0.364785  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Nombre d'observations: 2549, nombre de variables: 17\n"
     ]
    }
   ],
   "source": [
    " \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vocabulary = list(word_dist_top200[word_dist_top200[\"Frequency\"]>=1000].index)\n",
    "tfidf_vectorizer = TfidfVectorizer(vocabulary=vocabulary)\n",
    "X = tfidf_vectorizer.fit_transform(top200_joined_corpus)\n",
    "tfidf_data = pd.DataFrame(X.toarray(), columns=vocabulary)\n",
    "print(\"Affichage des 10 premiers posts vectorisés via le modèle de TF-IDF\")\n",
    "display(tfidf_data.head(10))\n",
    "print(f\" Nombre d'observations: {tfidf_data.shape[0]}, nombre de variables: {tfidf_data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc5b66b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affichage des 10 premiers posts vectorisés via le modèle de TF-IDF\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>java</th>\n",
       "      <th>error</th>\n",
       "      <th>name</th>\n",
       "      <th>version</th>\n",
       "      <th>file</th>\n",
       "      <th>import</th>\n",
       "      <th>class</th>\n",
       "      <th>code</th>\n",
       "      <th>http</th>\n",
       "      <th>return</th>\n",
       "      <th>line</th>\n",
       "      <th>value</th>\n",
       "      <th>type</th>\n",
       "      <th>function</th>\n",
       "      <th>const</th>\n",
       "      <th>path</th>\n",
       "      <th>python</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.592482</td>\n",
       "      <td>0.684021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.425536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.969166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584327</td>\n",
       "      <td>0.150171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.351158</td>\n",
       "      <td>0.294742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370111</td>\n",
       "      <td>0.537442</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.621957</td>\n",
       "      <td>0.783052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.725276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.931092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       java     error      name  version      file    import  class      code  \\\n",
       "0  0.000000  1.000000  0.000000      0.0  0.000000  0.000000    0.0  0.000000   \n",
       "1  0.592482  0.684021  0.000000      0.0  0.425536  0.000000    0.0  0.000000   \n",
       "2  0.000000  1.000000  0.000000      0.0  0.000000  0.000000    0.0  0.000000   \n",
       "3  0.000000  0.000000  0.000000      0.0  0.000000  0.000000    0.0  0.246409   \n",
       "4  0.000000  0.584327  0.150171      0.0  0.000000  0.000000    0.0  0.351158   \n",
       "5  0.000000  0.000000  0.000000      0.0  0.000000  0.000000    0.0  0.621957   \n",
       "6  0.000000  1.000000  0.000000      0.0  0.000000  0.000000    0.0  0.000000   \n",
       "7  0.000000  0.000000  0.688459      0.0  0.000000  0.725276    0.0  0.000000   \n",
       "8  0.000000  0.000000  0.000000      0.0  0.000000  0.000000    0.0  0.000000   \n",
       "9  0.000000  0.000000  0.000000      0.0  0.000000  0.000000    0.0  0.000000   \n",
       "\n",
       "       http    return  line     value  type  function     const      path  \\\n",
       "0  0.000000  0.000000   0.0  0.000000   0.0       0.0  0.000000  0.000000   \n",
       "1  0.000000  0.000000   0.0  0.000000   0.0       0.0  0.000000  0.000000   \n",
       "2  0.000000  0.000000   0.0  0.000000   0.0       0.0  0.000000  0.000000   \n",
       "3  0.000000  0.969166   0.0  0.000000   0.0       0.0  0.000000  0.000000   \n",
       "4  0.294742  0.000000   0.0  0.000000   0.0       0.0  0.370111  0.537442   \n",
       "5  0.783052  0.000000   0.0  0.000000   0.0       0.0  0.000000  0.000000   \n",
       "6  0.000000  0.000000   0.0  0.000000   0.0       0.0  0.000000  0.000000   \n",
       "7  0.000000  0.000000   0.0  0.000000   0.0       0.0  0.000000  0.000000   \n",
       "8  0.000000  0.000000   0.0  0.000000   0.0       0.0  0.000000  0.000000   \n",
       "9  0.000000  0.000000   0.0  0.931092   0.0       0.0  0.000000  0.000000   \n",
       "\n",
       "     python  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.000000  \n",
       "4  0.000000  \n",
       "5  0.000000  \n",
       "6  0.000000  \n",
       "7  0.000000  \n",
       "8  0.000000  \n",
       "9  0.364785  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Nombre d'observations: 2549, nombre de variables: 17\n"
     ]
    }
   ],
   "source": [
    " \n",
    "import pickle \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vocabulary = list(word_dist_top200[word_dist_top200[\"Frequency\"]>=1000].index)\n",
    "tfidf_vectorizer = TfidfVectorizer(vocabulary=vocabulary)\n",
    "X = tfidf_vectorizer.fit_transform(top200_joined_corpus)\n",
    "tfidf_data = pd.DataFrame(X.toarray(), columns=vocabulary)\n",
    "print(\"Affichage des 10 premiers posts vectorisés via le modèle de TF-IDF\")\n",
    "display(tfidf_data.head(10))\n",
    "print(f\" Nombre d'observations: {tfidf_data.shape[0]}, nombre de variables: {tfidf_data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "064751a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_tfidf_model = r'C:\\Users\\sesa638933\\Desktop\\OC\\P5\\tfidf_model.pkl'\n",
    "pickle.dump(tfidf_vectorizer, open(filename_tfidf_model, 'wb'))\n",
    "\n",
    "filename_vocabulary = r\"C:\\Users\\sesa638933\\Desktop\\OC\\P5\\vocabulary.pkl\"\n",
    "pickle.dump(vocabulary, open(filename_vocabulary, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc2e967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dedup_tags = []\n",
    "for tags in top200_tags:\n",
    "    dedup_tags.append(set(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fe74e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affichage de la première occurence de dedup_tags\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node', 'reactjs', 'webpack'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Affichage de la première occurence de dedup_tags')\n",
    "display(dedup_tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f77db83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_data, dedup_tags, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4738dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "164c91c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(random_state=42)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(random_state=42)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d34d45c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scree_plot(pca):\n",
    "    scree = pca.explained_variance_ratio_*100\n",
    "    plt.bar(np.arange(len(scree))+1, scree)\n",
    "    plt.plot(np.arange(len(scree))+1, scree.cumsum(),c=\"red\",marker='o')\n",
    "    plt.xlabel(\"rang de l'axe d'inertie\")\n",
    "    plt.ylabel(\"pourcentage d'inertie\")\n",
    "    plt.title(\"Eboulis des valeurs propres\")\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cc861cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_scree_plot(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ccf66e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de composantes principales: 13\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "pca = PCA(n_components=0.85, random_state=42)\n",
    "pca.fit(X_train)\n",
    "X_train_transformed = pca.transform(X_train)\n",
    "X_test_transformed = pca.transform(X_test)\n",
    "print(f\"Nombre de composantes principales: {pca.components_.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66ea966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_pca_model = r'C:\\Users\\sesa638933\\Desktop\\OC\\P5\\pca_model.pkl'\n",
    "pickle.dump(pca, open(filename_pca_model, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44679501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affichage des classes du modèle de vectorisation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['python', 'android', 'javascript', 'java', 'reactjs', 'react',\n",
       "       'studio', 'node', 'flutter', 'google', 'visual', 'typescript',\n",
       "       'github', 'docker', 'spring', 'azure', 'compose', 'kotlin',\n",
       "       'angular', 'swift', 'xcode', 'jetpack', 'core', 'native', 'amazon',\n",
       "       'html', 'algorithm', 'firebase', 'array', 'cloud', 'code',\n",
       "       'window', 'macos', 'service', 'kubernetes', 'boot', 'apache',\n",
       "       'router', 'gradle', 'data', 'panda', 'next', 'excel', 'dart',\n",
       "       'swiftui', 'rust', 'powershell', 'selenium', 'numpy', 'material',\n",
       "       'language', 'server', 'django', 'type', 'action', 'lawyer',\n",
       "       'spark', 'gitlab', 'laravel', 'webpack', 'framework', 'linux',\n",
       "       'blazor', 'security', 'apple', 'multithreading', 'ruby', 'list',\n",
       "       'tensorflow', 'testing', 'file', 'dataframe', 'authentication',\n",
       "       'error', 'string', 'navigation', 'generic', 'template', 'maven',\n",
       "       'hook', 'postgresql', 'lambda', 'ubuntu', 'pipeline', 'package',\n",
       "       'platform', 'matplotlib', 'json', 'function', 'optimization',\n",
       "       'dependency', 'nginx', 'module', 'image', 'http', 'performance',\n",
       "       'jupyter', 'loop', 'entity', 'pyspark', 'bash', 'discord',\n",
       "       'ggplot', 'databricks', 'compiler', 'sorting', 'rail', 'interface',\n",
       "       'oauth', 'mysql', 'eslint', 'express', 'manager', 'tailwind',\n",
       "       'terraform', 'memory', 'vscode', 'devops', 'processing', 'jestjs',\n",
       "       'mongodb', 'monterey', 'haskell', 'build', 'nestjs', 'play',\n",
       "       'library', 'redux', 'eclipse', 'database', 'regex', 'notebook',\n",
       "       'kafka', 'object', 'stream', 'webdriver', 'solana', 'nuxt',\n",
       "       'bootstrap', 'storage', 'chrome', 'opencv', 'typing', 'pytorch',\n",
       "       'jenkins', 'permission', 'unit', 'async', 'await', 'line',\n",
       "       'learning', 'programming', 'webassembly', 'tree', 'graph', 'kera',\n",
       "       'unity', 'vuejs', 'dplyr', 'scala', 'axios', 'logging', 'scikit',\n",
       "       'hibernate', 'learn', 'anaconda', 'command', 'dynamic', 'safari',\n",
       "       'recursion', 'time', 'plotly', 'script', 'ionic', 'plugin',\n",
       "       'xamarin', 'openssl', 'machine', 'math', 'collection', 'redis',\n",
       "       'ansible', 'conda', 'engine', 'cypress', 'form', 'import', 'apps',\n",
       "       'structure', 'sas', 'colaboratory', 'svelte', 'event',\n",
       "       'chromedriver', 'table', 'component', 'firestore', 'clang', 'user',\n",
       "       'mobile'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pickle \n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=first_200_tags)\n",
    "train_labels = mlb.fit_transform(y_train)\n",
    "test_labels = mlb.transform(y_test)\n",
    "\n",
    "print(\"Affichage des classes du modèle de vectorisation\")\n",
    "display(mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abcb53c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_mlb_model = r'C:\\Users\\sesa638933\\Desktop\\OC\\P5\\mlb_model.pkl'\n",
    "pickle.dump(mlb, open(filename_mlb_model,'wb'))\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, hamming_loss\n",
    "\n",
    "models_performance = {}\n",
    "\n",
    "def metrics_report(model_name, test_labels, predictions, performances):\n",
    "    \"\"\"\n",
    "    Compute performance metrics of a model and store them in a dictionary\n",
    "    \n",
    "    Args:\n",
    "        model_name(string): name of the evaluated model\n",
    "        test_labels(array): labels related to predictors\n",
    "        preductions(array): predicted results\n",
    "        performances(dict): used dictionary to store metrics\n",
    "    Returns:\n",
    "        performances(dict): used dictionary to store metrics filed with models ones\n",
    "    \"\"\"    \n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    macro_precision = precision_score(test_labels, predictions, average='macro')\n",
    "    macro_recall = recall_score(test_labels, predictions, average='macro')\n",
    "    macro_f1 = f1_score(test_labels, predictions, average='macro')\n",
    "    micro_precision = precision_score(test_labels, predictions, average='micro')\n",
    "    micro_recall = recall_score(test_labels, predictions, average='micro')\n",
    "    micro_f1 = f1_score(test_labels, predictions, average='micro')\n",
    "    hamLoss = hamming_loss(test_labels, predictions)\n",
    "    print(\"------\" + model_name + \" Model Metrics-----\")\n",
    "    print(\"Accuracy: {:.4f}\\nHamming Loss: {:.4f}\\nPrecision:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\\nRecall:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\\nF1-measure:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\"\\\n",
    "          .format(accuracy, hamLoss, macro_precision, micro_precision, macro_recall, micro_recall, macro_f1, micro_f1))\n",
    "\n",
    "    \n",
    "    performances[model_name] = {}\n",
    "    performances[model_name][\"micro_precision\"] =  micro_precision\n",
    "    performances[model_name][\"micro_recall\"] = micro_recall\n",
    "    performances[model_name][\"micro_f1\"] = micro_f1\n",
    "    \n",
    "    return performances\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85cc846f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------knn Model Metrics-----\n",
      "Accuracy: 0.0098\n",
      "Hamming Loss: 0.0121\n",
      "Precision:\n",
      "  - Macro: 0.0425\n",
      "  - Micro: 0.4786\n",
      "Recall:\n",
      "  - Macro: 0.0099\n",
      "  - Micro: 0.0543\n",
      "F1-measure:\n",
      "  - Macro: 0.0143\n",
      "  - Micro: 0.0976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sesa638933\\Anaconda3\\conda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sesa638933\\Anaconda3\\conda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sesa638933\\Anaconda3\\conda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn': {'micro_precision': 0.4785714285714286,\n",
       "  'micro_recall': 0.054339010543390104,\n",
       "  'micro_f1': 0.09759650400582665}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train_transformed, train_labels)\n",
    "knn_predictions = knn_clf.predict(X_test_transformed)\n",
    "metrics_report(\"knn\", test_labels, knn_predictions, models_performance)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf5b25d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------svm Model Metrics-----\n",
      "Accuracy: 0.0137\n",
      "Hamming Loss: 0.0118\n",
      "Precision:\n",
      "  - Macro: 0.0066\n",
      "  - Micro: 0.7213\n",
      "Recall:\n",
      "  - Macro: 0.0040\n",
      "  - Micro: 0.0357\n",
      "F1-measure:\n",
      "  - Macro: 0.0049\n",
      "  - Micro: 0.0680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sesa638933\\Anaconda3\\conda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sesa638933\\Anaconda3\\conda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sesa638933\\Anaconda3\\conda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn': {'micro_precision': 0.4785714285714286,\n",
       "  'micro_recall': 0.054339010543390104,\n",
       "  'micro_f1': 0.09759650400582665},\n",
       " 'svm': {'micro_precision': 0.7213114754098361,\n",
       "  'micro_recall': 0.035685320356853206,\n",
       "  'micro_f1': 0.06800618238021638}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "svm_clf = OneVsRestClassifier(LinearSVC(), n_jobs=-1)\n",
    "svm_clf.fit(X_train_transformed, train_labels)\n",
    "\n",
    "svm_preds = svm_clf.predict(X_test_transformed)\n",
    "metrics_report(\"svm\", test_labels, svm_preds, models_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7116d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Random Forest Model Metrics-----\n",
      "Accuracy: 0.0118\n",
      "Hamming Loss: 0.0123\n",
      "Precision:\n",
      "  - Macro: 0.0153\n",
      "  - Micro: 0.4107\n",
      "Recall:\n",
      "  - Macro: 0.0044\n",
      "  - Micro: 0.0373\n",
      "F1-measure:\n",
      "  - Macro: 0.0057\n",
      "  - Micro: 0.0684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sesa638933\\Anaconda3\\conda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sesa638933\\Anaconda3\\conda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sesa638933\\Anaconda3\\conda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn': {'micro_precision': 0.4785714285714286,\n",
       "  'micro_recall': 0.054339010543390104,\n",
       "  'micro_f1': 0.09759650400582665},\n",
       " 'svm': {'micro_precision': 0.7213114754098361,\n",
       "  'micro_recall': 0.035685320356853206,\n",
       "  'micro_f1': 0.06800618238021638},\n",
       " 'Random Forest': {'micro_precision': 0.4107142857142857,\n",
       "  'micro_recall': 0.0373073803730738,\n",
       "  'micro_f1': 0.06840148698884758}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(n_jobs=-1)\n",
    "rf_clf.fit(X_train_transformed, train_labels)\n",
    "rf_preds = rf_clf.predict(X_test_transformed)\n",
    "metrics_report(\"Random Forest\", test_labels, rf_preds, models_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "gb_clf = OneVsRestClassifier(GradientBoostingClassifier())\n",
    "gb_clf.fit(X_train_transformed, train_labels)\n",
    "gb_preds = gb_clf.predict(X_test_transformed)\n",
    "metrics_report(\"Gradient Boosting\", test_labels, gb_preds, models_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257d479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename_svm_model = r'C:\\Users\\sesa638933\\Desktop\\OC\\P5\\svm_model.pkl'\n",
    "pickle.dump(svm_clf, open(filename_svm_model,'wb'))\n",
    "\n",
    " \n",
    "def predict_supervised_tags(supervised_model, mlb_model, text):\n",
    "    \"\"\"\n",
    "    Predict tags according to a lemmatized text using a supervied model.\n",
    "    \n",
    "    Args:\n",
    "        supervised_model(): Used mode to get prediction\n",
    "        mlb_model(): Used model to detransform\n",
    "    Returns:\n",
    "        res(list): List of predicted tags\n",
    "    \"\"\"\n",
    "    res = tfidf_vectorizer.transform(text)\n",
    "    res = pd.DataFrame(res.toarray(), columns=vocabulary)\n",
    "    res = pca.transform(res)\n",
    "    res = supervised_model.predict(res)\n",
    "    res = mlb.inverse_transform(res)\n",
    "    res = list({tag for tag_list in res for tag in tag_list if (len(tag_list) != 0)})\n",
    "    res = [tag for tag  in res if tag in text]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e0b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tag_predction(original_text, original_tags, preprocessed_text, model):\n",
    "    \"\"\"\n",
    "    Check original tags vs predicted tags for a post.\n",
    "    \n",
    "    Args:\n",
    "        post(list) : original text\n",
    "        original_tags(list) : preprocessed_tags\n",
    "    \"\"\"\n",
    "    \n",
    "    predicted_tags = predict_supervised_tags(model, mlb, preprocessed_text)\n",
    "    print(\"Publication originale: \\n\")\n",
    "    print(f\"{original_text}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"Liste des tags pré-traités utilisés par l'utilisateur: {original_tags}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"Liste des tags prédits par le modèle: {predicted_tags}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabadded",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_tag_predction(filtered_tokenized_vs_original.loc[0,'Post'], \n",
    "                filtered_tokenized_vs_original.loc[0,'splitted_tags'],\n",
    "                filtered_tokenized_vs_original.loc[0,'splitted_text'],\n",
    "                svm_clf)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7120da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim import models\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models import CoherenceModel\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start, step):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Args:\n",
    "  \n",
    "        dictionary : Gensim dictionary\n",
    "        corpus : Gensim corpus\n",
    "        texts : List of input texts\n",
    "        limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    \n",
    "        model_list : List of LDA topic models\n",
    "        coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "        \n",
    "    \n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LdaMulticore(corpus=corpus,\n",
    "                            id2word=dictionary,\n",
    "                            num_topics=num_topics, \n",
    "                            random_state=42,\n",
    "                            passes=10,\n",
    "                            workers=7)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "        \n",
    "    return model_list, coherence_values\n",
    "\n",
    "data = pd.read_pickle(r\"C:\\Users\\sesa638933\\Desktop\\OC\\P5\\cleaned_corpus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1318c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data['splitted_text']\n",
    "id2word = Dictionary(texts)\n",
    "id2word.filter_extremes(no_below=200)\n",
    "bow_corpus = [id2word.doc2bow(text) for text in texts]\n",
    "tfidf = TfidfModel(bow_corpus)\n",
    "tfidf_corpus = [tfidf[text] for text in bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc4cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(id2word, tfidf_corpus, texts, start=2, limit=10, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cac61c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1061f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de45c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=10; start=2; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()\n",
    "\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e95112",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pprint import pprint\n",
    "optimal_model = model_list[0]\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=optimal_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db61f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "original_post = data['Post']\n",
    "original_cleaned_keywords = data['splitted_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13dfeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=tfidf_corpus, texts=original_post)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic = pd.concat([df_dominant_topic, original_cleaned_keywords], axis=1)\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text', 'Original_keywords']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b039519",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "sent_topics_sorteddf = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf = pd.concat([sent_topics_sorteddf, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ae81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = sent_topics_sorteddf[[\"Topic_Num\",\"Keywords\"]]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics_prop = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics_prop.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a0db9d",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "from IPython.display import HTML\n",
    "css_str = '<style> \\\n",
    ".jp-icon-warn0 path {fill: var(--jp-warn-color0);} \\\n",
    ".bp3-button-text path { fill: var(--jp-inverse-layout-color3);} \\\n",
    ".jp-icon-brand0 path { fill: var(--jp-brand-color0);} \\\n",
    "text.terms { fill: #616161;} \\\n",
    "</style>'\n",
    "display(HTML(css_str))\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(optimal_model, tfidf_corpus, id2word)\n",
    "pyLDAvis.save_html(vis, 'lda_tfidf.html')\n",
    "display(HTML('lda_tfidf.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d757611",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = optimal_model\n",
    "def predict_unsupervised_tags(text):\n",
    "    \"\"\"\n",
    "    Predict tags of a preprocessed text\n",
    "    \n",
    "    Args:\n",
    "        text(list): preprocessed text\n",
    "        \n",
    "    Returns:\n",
    "        relevant_tags(list): list of tags\n",
    "    \"\"\"\n",
    "    \n",
    "    corpus_new = id2word.doc2bow(text)\n",
    "    topics = lda_model.get_document_topics(corpus_new)\n",
    "    \n",
    "    #find most relevant topic according to probability\n",
    "    relevant_topic = topics[0][0]\n",
    "    relevant_topic_prob = topics[0][1]\n",
    "    \n",
    "    for i in range(len(topics)):\n",
    "        if topics[i][1] > relevant_topic_prob:\n",
    "            relevant_topic = topics[i][0]\n",
    "            relevant_topic_prob = topics[i][1]\n",
    "            \n",
    "    #retrieve associated to topic tags present in submited text\n",
    "    potential_tags = lda_model.get_topic_terms(topicid=relevant_topic, topn=20)\n",
    "    \n",
    "    relevant_tags = [id2word[tag[0]] for tag in potential_tags if id2word[tag[0]] in text]\n",
    "    \n",
    "    return relevant_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb93041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_tag_predction(original_text, original_tags, preprocessed_text, supervised_model):\n",
    "    \"\"\"\n",
    "    Check original tags vs predicted tags for a post.\n",
    "    \n",
    "    Args:\n",
    "        post(list) : original text\n",
    "        original_tags(list) : preprocessed_tags\n",
    "    \"\"\"\n",
    "    \n",
    "    predicted_supervised_tags = predict_supervised_tags(supervised_model, mlb, preprocessed_text)\n",
    "    predicted_unsupervised_tags = predict_unsupervised_tags(preprocessed_text)\n",
    "    print(\"Publication originale: \\n\")\n",
    "    print(f\"{original_text}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"Liste des tags pré-traités utilisés par l'utilisateur: {original_tags}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"Liste des tags prédits par le modèle supervisé: {predicted_supervised_tags}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"Liste des tags prédits par le modèle non supervisé: {predicted_unsupervised_tags}\")\n",
    "    return(original_tags,predicted_supervised_tags,predicted_unsupervised_tags)\n",
    "   \n",
    "origine=[]\n",
    "superv=[]\n",
    "nsuperv=[]\n",
    "\n",
    "print(\"Test des 10 premiers documents du corpus\\n\")\n",
    "for i in range(25):\n",
    "    print(f\"Document {i}:\")\n",
    "    print(\"\\n\")\n",
    "    a,b,c=check_tag_predction(filtered_tokenized_vs_original.loc[i,'Post'], \n",
    "                    filtered_tokenized_vs_original.loc[i,'splitted_tags'],\n",
    "                    filtered_tokenized_vs_original.loc[i,'splitted_text'],\n",
    "                    svm_clf)\n",
    "    origine.append(a)\n",
    "    superv.append(b)\n",
    "    nsuperv.append(c)\n",
    "    print(\"-\"*100 + \"\\n\")\n",
    "df=pd.DataFrame([origine,superv,nsuperv])\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a299077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538a59e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.rename(columns={0: 'pré-traités', 1: 'approche supervisée', 2: 'approche non supervisée'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e747b0ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "filename_model = r'C:\\Users\\sesa638933\\Desktop\\OC\\P5\\lda_model.pkl'\n",
    "pickle.dump(lda_model, open(filename_model,'wb'))\n",
    "\n",
    "\n",
    "\n",
    "filename_dictionary = r'C:\\Users\\sesa638933\\Desktop\\OC\\P5\\dictionary.pkl'\n",
    "pickle.dump(id2word, open(filename_dictionary,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e43f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lxml\n",
    "import html5lib\n",
    "import re\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim import models\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "def clean_html(text):\n",
    "    \"\"\"\n",
    "    Remove HTML from a text.\n",
    "    \n",
    "    Args:\n",
    "        text(String): Row text with html       \n",
    "    Returns:\n",
    "        cleaned String\n",
    "    \"\"\" \n",
    "    soup = BeautifulSoup(text, \"html5lib\")\n",
    "\n",
    "    for sent in soup(['style', 'script']):\n",
    "            sent.decompose()\n",
    "    \n",
    "    return ' '.join(soup.stripped_strings)\n",
    "\n",
    "def text_cleaning(text):\n",
    "    \"\"\"\n",
    "    Remove figures, punctuation, words shorter than two letters (excepted C or R) in a lowered text. \n",
    "    \n",
    "    Args:\n",
    "        text(String): Row text to clean  \n",
    "    Returns:\n",
    "        res(string): Cleaned text\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r'[^\\w]|[\\d_]')\n",
    "    \n",
    "    try: \n",
    "        res = re.sub(pattern,\" \", text).lower()\n",
    "    except TypeError:\n",
    "        return text\n",
    "    \n",
    "    res = res.split(\" \")\n",
    "    res = list(filter(lambda x: len(x)>3 , res)) #Keep singles c and r because it might be used as name of languages\n",
    "    res = \" \".join(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize words of a text.\n",
    "    \n",
    "    Args:\n",
    "        text(String): Row text\n",
    "    Returns\n",
    "        res(list): Tokenized string.\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    try:\n",
    "        res = word_tokenize(text, language='english')\n",
    "    except TypeError:\n",
    "        return text\n",
    "    \n",
    "    res = [token for token in res if token not in stop_words]\n",
    "    return res\n",
    "\n",
    "def filtering_nouns(tokens):\n",
    "    \"\"\"\n",
    "    Filter singular nouns\n",
    "    \n",
    "    Args:\n",
    "        tokens(list): A list o tokens\n",
    "        \n",
    "    Returns:\n",
    "    \n",
    "        res(list): Filtered token list\n",
    "    \"\"\" \n",
    "    res = nltk.pos_tag(tokens)\n",
    "    \n",
    "    res = [token[0] for token in res if token[1] == 'NN']\n",
    "    \n",
    "    return res\n",
    "    \n",
    "def lemmatize(tokens):\n",
    "    \"\"\"\n",
    "    Transform tokens into lems \n",
    "    \n",
    "    Args:\n",
    "        tokens(list): List of tokens       \n",
    "    Returns:\n",
    "        lemmatized(list): List of lemmatized tokens\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        lemmatized.append(lemmatizer.lemmatize(token))\n",
    "        \n",
    "    return lemmatized\n",
    "\n",
    "\n",
    "class LdaModel:\n",
    "\n",
    "    def __init__(self):\n",
    "        filename_model = r\"C:\\Users\\sesa638933\\Desktop\\OC\\P5\\lda_model.pkl\"\n",
    "        filename_dictionary = r\"C:\\Users\\sesa638933\\Desktop\\OC\\P5\\dictionary.pkl\"\n",
    "        self.model = pickle.load(open(filename_model, 'rb'))\n",
    "        self.dictionary = pickle.load(open(filename_dictionary, 'rb'))\n",
    "\n",
    "    def predict_tags(self, text):\n",
    "        \"\"\"\n",
    "        Predict tags\n",
    "        zof a preprocessed text\n",
    "        \n",
    "        Args:\n",
    "            text(list): preprocessed text\n",
    "        Returns:\n",
    "            res(list): list of tags\n",
    "        \"\"\"\n",
    "        corpus_new = self.dictionary.doc2bow(text)\n",
    "        topics = self.model.get_document_topics(corpus_new)\n",
    "        \n",
    "        #find most relevant topic according to probability\n",
    "        relevant_topic = topics[0][0]\n",
    "        relevant_topic_prob = topics[0][1]\n",
    "        \n",
    "        for i in range(len(topics)):\n",
    "            if topics[i][1] > relevant_topic_prob:\n",
    "                relevant_topic = topics[i][0]\n",
    "                relevant_topic_prob = topics[i][1]\n",
    "                \n",
    "        #retrieve associated to topic tags present in submited text\n",
    "        res = self.model.get_topic_terms(topicid=relevant_topic, topn=20)\n",
    "        \n",
    "        res = [self.dictionary[tag[0]] for tag in res if self.dictionary[tag[0]] in text]\n",
    "        \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04d2f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "\n",
    "text = input()\n",
    "\n",
    "text_wo_html = clean_html(text)\n",
    "cleaned_text = text_cleaning(text_wo_html)\n",
    "tokenized_text = tokenize(cleaned_text)\n",
    "filtered_noun_text = filtering_nouns(tokenized_text)\n",
    "lemmatized_text = lemmatization(filtered_noun_text)\n",
    "unsupervised_tags = predict_unsupervised_tags(lemmatized_text)\n",
    "\n",
    "unsupervised_tags\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eefafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7161d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e270f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
